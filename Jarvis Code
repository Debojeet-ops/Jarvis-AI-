import datetime
import os
import random
import webbrowser
import cv2
import numpy as np
import pyttsx3
import speech_recognition as sr
from PIL import Image

# Initialize text-to-speech
engine = pyttsx3.init()
voices = engine.getProperty('voices')
engine.setProperty('voice', voices[0].id)

# Speak function
def speak(audio):
    print(f"Assistant: {audio}")
    engine.say(audio)
    engine.runAndWait()

# Welcome user
def wishme():
    hour = int(datetime.datetime.now().hour)
    greeting = "Good Morning!" if hour < 12 else "Good Afternoon!" if hour < 18 else "Good Evening!"
    speak(f"{greeting} I am your voice assistant. How can I assist you today?")

# Function to listen for voice input
def take_command():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        r.pause_threshold = 1
        audio = r.listen(source)
    try:
        print("Recognizing...")
        query = r.recognize_google(audio, language='en-in')
        print(f"User said: {query}\n")
    except:
        print("Could not understand. Please repeat.")
        return "none"
    return query.lower()

# Simple AI chatbot responses
def chatbot_response(query):
    responses = {
        "hello": ["Hi Debojeet how can I help you", "Hello! Debojeet after a long time", "Hey! Debojeet let's start"],
        "how are you": ["I'm just a program, but I'm doing great!", "I'm fine, thanks for asking!", "I'm always here to help!"],
        "what is your name": ["Call me Jarvis!"],
        "who made you": ["I was created by a Debojeet"],
        "bye": ["Goodbye!", "See you later!", "Take care!"]
    }
    for key in responses:
        if key in query:
            return random.choice(responses[key])
    return "I didn't understand that. Can you rephrase?"

# Function to search Google
browser_tab_opened = False

def search_google(query):
    global browser_tab_opened
    url = f"https://www.google.com/search?q={query.replace(' ', '+')}"
    if not browser_tab_opened:
        webbrowser.open(url)
        browser_tab_opened = True
    else:
        webbrowser.get().open_new_tab(url)
    speak(f"Searching Google for {query}")

# Function to search on YouTube
def search_youtube(query):
    search_url = f"https://www.youtube.com/results?search_query={query.replace(' ', '+')}"
    webbrowser.open(search_url)
    speak(f"Searching YouTube for {query}")

# Function to open a website
def open_website(name, url):
    webbrowser.open(url)
    speak(f"Opening {name}.")

# Face data collection and training

def collect_and_train_faces():
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    recognizer = cv2.face.LBPHFaceRecognizer_create()

    user_id = 1
    count = 0
    os.makedirs("face_dataset", exist_ok=True)
    cam = cv2.VideoCapture(0)
    speak("Please look at the camera to collect face data.")

    while True:
        ret, frame = cam.read()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x, y, w, h) in faces:
            count += 1
            cv2.imwrite(f"face_dataset/User.{user_id}.{count}.jpg", gray[y:y+h, x:x+w])
            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)

        cv2.imshow("Collecting Faces", frame)

        if cv2.waitKey(1) & 0xFF == ord('q') or count >= 30:
            break

    cam.release()
    cv2.destroyAllWindows()
    speak("Face data collection complete. Training recognizer now.")

    # Training
    face_samples = []
    ids = []
    image_paths = [os.path.join("face_dataset", f) for f in os.listdir("face_dataset")]
    for imagePath in image_paths:
        gray_img = Image.open(imagePath).convert('L')
        img_np = np.array(gray_img, 'uint8')
        user_id = int(imagePath.split('.')[1])

        faces = face_cascade.detectMultiScale(img_np)
        for (x, y, w, h) in faces:
            face_samples.append(img_np[y:y+h, x:x+w])
            ids.append(user_id)

    recognizer.train(face_samples, np.array(ids))
    recognizer.save("trainer.yml")
    speak("Training complete. Face recognition system is ready.")

# Face recognition unlock system
def face_unlock():
    if not os.path.exists("trainer.yml"):
        collect_and_train_faces()

    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read("trainer.yml")

    cam = cv2.VideoCapture(0)
    speak("Face recognition activated. Please look at the camera.")

    while True:
        ret, frame = cam.read()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x, y, w, h) in faces:
            id_, conf = recognizer.predict(gray[y:y+h, x:x+w])
            if conf < 70:
                speak("Face recognized. Welcome back.")
                cam.release()
                cv2.destroyAllWindows()
                run_assistant()
                return

        cv2.imshow('Face Recognition', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cam.release()
    cv2.destroyAllWindows()

# Main function
def run_assistant():
    wishme()

    while True:
        query = take_command()
        if query == "none":
            continue

        elif any(word in query for word in ["hello", "how are you", "your name", "who made you", "bye"]):
            response = chatbot_response(query)
            print(response)
            speak(response)

        elif 'search youtube for' in query or 'play on youtube' in query:
            video_query = query.replace('search youtube for', '').replace('play on youtube', '').strip()
            search_youtube(video_query)

        elif 'open youtube' in query:
            open_website("YouTube", "https://youtube.com")
        elif 'open google' in query:
            open_website("Google", "https://google.com")
        elif 'open whatsapp' in query:
            open_website("WhatsApp", "https://web.whatsapp.com")
        elif 'open spotify' in query:
            open_website("Spotify", "https://spotify.com")
        elif 'open github' in query:
            open_website("GitHub", "https://github.com")

        elif 'the time' in query:
            strTime = datetime.datetime.now().strftime("%H:%M:%S")
            speak(f"The time is {strTime}")

        elif 'shutdown' in query:
            speak("Shutting down the system.")
            os.system("shutdown /s /t 5")
            break

        elif 'exit' in query or 'stop' in query:
            speak("Okay, entering sleep mode. Show me your face to activate again.")
            sleep_mode()

        else:
            search_google(query)

# Sleep mode waits for authorized face
def sleep_mode():
    face_unlock()

# Start the assistant
speak("I am your voice assistant. Show me your face to start.")
sleep_mode()
